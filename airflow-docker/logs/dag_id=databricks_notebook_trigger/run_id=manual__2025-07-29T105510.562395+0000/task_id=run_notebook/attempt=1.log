{"timestamp":"2025-07-29T10:55:15.286703","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-07-29T10:55:15.291271","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/trigger_databricks_notebook.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-29T10:55:16.564247Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-29T10:55:16.564875Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-29T10:55:16.565557Z","level":"info","event":"Current task name:run_notebook","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-29T10:55:16.565922Z","level":"info","event":"Dag name:databricks_notebook_trigger","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-29T10:55:16.619238","level":"info","event":"Connection Retrieved 'databricks'","logger":"airflow.hooks.base"}
{"timestamp":"2025-07-29T10:55:16.632430","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T10:55:19.026505","level":"info","event":"Run submitted with run_id: 1108091884562042","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T10:55:19.027059","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T10:55:20.379948","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T10:55:22.012167","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T10:55:22.012885","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/198604782450392/run/1108091884562042","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T10:55:22.013026","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T10:55:52.493942","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T10:55:53.919329","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T10:55:53.919519","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/198604782450392/run/1108091884562042","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T10:55:53.919607","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T10:56:24.377810","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T10:56:26.235459","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T10:56:26.235609","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/198604782450392/run/1108091884562042","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T10:56:26.235671","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T10:56:56.236472","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T10:56:57.563768","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T10:56:57.564107","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/198604782450392/run/1108091884562042","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T10:56:57.564495","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T10:57:27.986563","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T10:57:29.460438","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T10:57:29.460694","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/198604782450392/run/1108091884562042","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T10:57:29.460794","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T10:57:59.998160","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T10:58:01.305303","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T10:58:01.305570","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/198604782450392/run/1108091884562042","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T10:58:01.305680","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T10:58:31.709147","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T10:58:33.647724","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T10:58:33.648143","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/198604782450392/run/1108091884562042","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T10:58:33.648275","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T10:59:04.209325","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T10:59:05.641102","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T10:59:05.641248","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/198604782450392/run/1108091884562042","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T10:59:05.641303","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T10:59:36.066956","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T10:59:37.604288","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T10:59:37.604518","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/198604782450392/run/1108091884562042","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T10:59:37.604619","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:00:08.194330","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:00:10.012728","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:00:10.012926","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/198604782450392/run/1108091884562042","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:00:10.013924","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:00:40.563890","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:00:41.875880","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:00:41.876097","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/198604782450392/run/1108091884562042","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:00:41.876208","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:01:11.877371","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:01:13.395578","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:01:14.986002","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"AirflowException","exc_value":"run_notebook failed with terminal state: {'life_cycle_state': 'INTERNAL_ERROR', 'result_state': 'FAILED', 'state_message': \"Cluster '0729-105520-tnkhs78i' was terminated. Reason: AZURE_QUOTA_EXCEEDED_EXCEPTION (CLIENT_ERROR). Parameters: databricks_error_message:The VM size you are specifying is not available. [details] QuotaExceeded: Operation could not be completed as it results in exceeding approved Total Regional Cores quota. Additional details - Deployment Model: Resource Manager, Location: eastus, Current Limit: 4, Current Usage: 4, Additional Required: 4, (Minimum) New Limit Required: 8. Setup Alerts when Quota reaches threshold. Learn more at https://aka.ms/quotamonitoringalerting . Submit a request for Quota increase at https://aka.ms/ProdportalCRP/#blade/Microsoft_Azure_Capacity/UsageAndQuota.ReactView/Parameters/%7B%22subscriptionId%22:%229c7614db-b553-43c6-b864-5133739e04b5%22,%22command%22:%22openQuotaApprovalBlade%22,%22quotas%22:[%7B%22location%22:%22eastus%22,%22providerId%22:%22Microsoft.Comp ...\\n***WARNING: message truncated. Skipped 1585 bytes of output**\\n\\n\"} and with the errors [{'task_key': 'run_notebook', 'run_id': 1108091884562042, 'error': \"Run failed with error message\\n Cluster '0729-105520-tnkhs78i' was terminated. Reason: AZURE_QUOTA_EXCEEDED_EXCEPTION (CLIENT_ERROR). Parameters: databricks_error_message:The VM size you are specifying is not available. [details] QuotaExceeded: Operation could not be completed as it results in exceeding approved Total Regional Cores quota. Additional details - Deployment Model: Resource Manager, Location: eastus, Current Limit: 4, Current Usage: 4, Additional Required: 4, (Minimum) New Limit Required: 8. Setup Alerts when Quota reaches threshold. Learn more at https://aka.ms/quotamonitoringalerting . Submit a request for Quota increase at https://aka.ms/ProdportalCRP/#blade/Microsoft_Azure_Capacity/UsageAndQuota.ReactView/Parameters/%7B%22subscriptionId%22:%229c7614db-b553-43c6-b864-5133739e04b5%22,%22command%22:%22openQuotaApprovalBlade%22,%22quotas%22:[%7B%22location%22:%22eastus%22,%22providerId%22:%22Microsoft.Comp ...\\n***WARNING: message truncated. Skipped 1585 bytes of output**\\n\\n\"}]","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":877,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1164,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":397,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/databricks/operators/databricks.py","lineno":645,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/databricks/operators/databricks.py","lineno":143,"name":"_handle_databricks_operator_execution"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2025-07-29T11:01:15.212057Z","level":"info","event":"Task instance in failure state","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-29T11:01:15.220308Z","level":"info","event":"Task start","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-29T11:01:15.220899Z","level":"info","event":"Task:<Task(DatabricksSubmitRunOperator): run_notebook>","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-29T11:01:15.221254Z","level":"info","event":"Failure caused by run_notebook failed with terminal state: {'life_cycle_state': 'INTERNAL_ERROR', 'result_state': 'FAILED', 'state_message': \"Cluster '0729-105520-tnkhs78i' was terminated. Reason: AZURE_QUOTA_EXCEEDED_EXCEPTION (CLIENT_ERROR). Parameters: databricks_error_message:The VM size you are specifying is not available. [details] QuotaExceeded: Operation could not be completed as it results in exceeding approved Total Regional Cores quota. Additional details - Deployment Model: Resource Manager, Location: eastus, Current Limit: 4, Current Usage: 4, Additional Required: 4, (Minimum) New Limit Required: 8. Setup Alerts when Quota reaches threshold. Learn more at https://aka.ms/quotamonitoringalerting . Submit a request for Quota increase at https://aka.ms/ProdportalCRP/#blade/Microsoft_Azure_Capacity/UsageAndQuota.ReactView/Parameters/%7B%22subscriptionId%22:%229c7614db-b553-43c6-b864-5133739e04b5%22,%22command%22:%22openQuotaApprovalBlade%22,%22quotas%22:[%7B%22location%22:%22eastus%22,%22providerId%22:%22Microsoft.Comp ...\\n***WARNING: message truncated. Skipped 1585 bytes of output**\\n\\n\"} and with the errors [{'task_key': 'run_notebook', 'run_id': 1108091884562042, 'error': \"Run failed with error message\\n Cluster '0729-105520-tnkhs78i' was terminated. Reason: AZURE_QUOTA_EXCEEDED_EXCEPTION (CLIENT_ERROR). Parameters: databricks_error_message:The VM size you are specifying is not available. [details] QuotaExceeded: Operation could not be completed as it results in exceeding approved Total Regional Cores quota. Additional details - Deployment Model: Resource Manager, Location: eastus, Current Limit: 4, Current Usage: 4, Additional Required: 4, (Minimum) New Limit Required: 8. Setup Alerts when Quota reaches threshold. Learn more at https://aka.ms/quotamonitoringalerting . Submit a request for Quota increase at https://aka.ms/ProdportalCRP/#blade/Microsoft_Azure_Capacity/UsageAndQuota.ReactView/Parameters/%7B%22subscriptionId%22:%229c7614db-b553-43c6-b864-5133739e04b5%22,%22command%22:%22openQuotaApprovalBlade%22,%22quotas%22:[%7B%22location%22:%22eastus%22,%22providerId%22:%22Microsoft.Comp ...\\n***WARNING: message truncated. Skipped 1585 bytes of output**\\n\\n\"}]","chan":"stdout","logger":"task"}
