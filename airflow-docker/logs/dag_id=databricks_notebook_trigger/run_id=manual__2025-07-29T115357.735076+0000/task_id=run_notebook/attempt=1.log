{"timestamp":"2025-07-29T11:54:02.699416","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-07-29T11:54:02.701477","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/trigger_databricks_notebook.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-29T11:54:02.924563Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-29T11:54:02.928194Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-29T11:54:02.929200Z","level":"info","event":"Current task name:run_notebook","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-29T11:54:02.929815Z","level":"info","event":"Dag name:databricks_notebook_trigger","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-29T11:54:02.981048","level":"info","event":"Connection Retrieved 'databricks'","logger":"airflow.hooks.base"}
{"timestamp":"2025-07-29T11:54:02.988332","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:54:05.550289","level":"info","event":"Run submitted with run_id: 533508885115850","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:54:05.550586","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:54:06.763591","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:54:08.171124","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:54:08.171328","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/842498987919265/run/533508885115850","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:54:08.171455","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:54:38.749306","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:54:40.308113","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:54:40.308386","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/842498987919265/run/533508885115850","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:54:40.308488","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:55:10.873843","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:55:12.539228","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:55:12.539470","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/842498987919265/run/533508885115850","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:55:12.539588","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:55:43.109461","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:55:44.366347","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:55:44.366563","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/842498987919265/run/533508885115850","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:55:44.366664","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:56:14.937154","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:56:16.745839","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:56:16.746176","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/842498987919265/run/533508885115850","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:56:16.746359","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:56:47.337431","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:56:48.951155","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:56:48.951501","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/842498987919265/run/533508885115850","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:56:48.951663","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:57:19.533070","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:57:22.583483","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:57:22.583677","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/842498987919265/run/533508885115850","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:57:22.583797","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:57:53.208222","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:57:54.564590","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:57:54.564828","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/842498987919265/run/533508885115850","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:57:54.564937","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:58:25.182725","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:58:26.898669","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:58:26.898891","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/842498987919265/run/533508885115850","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:58:26.898976","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:58:57.445010","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:58:59.215823","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:58:59.216166","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/842498987919265/run/533508885115850","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:58:59.216285","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:59:29.708647","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:59:31.338332","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:59:31.338539","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/842498987919265/run/533508885115850","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:59:31.338631","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:00:01.917027","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T12:00:03.568506","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:00:03.568791","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/842498987919265/run/533508885115850","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:00:03.568905","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:00:34.106148","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T12:00:35.835216","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:00:35.835350","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/842498987919265/run/533508885115850","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:00:35.835409","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:01:06.458312","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T12:01:08.503104","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:01:08.503426","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/842498987919265/run/533508885115850","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:01:08.503571","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:01:39.027079","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T12:01:40.867445","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:01:40.867705","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/842498987919265/run/533508885115850","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:01:40.867904","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:02:10.868542","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T12:02:12.863987","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:02:12.864178","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/842498987919265/run/533508885115850","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:02:12.864319","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:02:43.926226","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T12:02:45.549178","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:02:45.549396","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/842498987919265/run/533508885115850","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:02:45.549492","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:03:16.172800","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T12:03:17.805581","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:03:17.805808","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/842498987919265/run/533508885115850","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:03:17.805909","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:03:47.806680","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T12:03:49.956057","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:03:49.956314","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/842498987919265/run/533508885115850","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:03:49.956420","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:04:19.957233","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T12:04:22.081245","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:04:22.081495","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/842498987919265/run/533508885115850","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:04:22.081607","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:04:52.086743","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T12:04:57.947471","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:04:57.947890","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/842498987919265/run/533508885115850","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:04:57.948049","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:05:28.494435","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T12:05:30.256847","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:05:30.257241","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/842498987919265/run/533508885115850","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:05:30.257396","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T12:06:00.258737","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T12:10:21.139867","level":"error","event":"Attempt 1 API Request to Databricks failed with reason: <Future at 0x756585a8aa50 state=finished raised ReadTimeout>","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T12:10:23.984431","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T12:10:25.369642","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"AirflowException","exc_value":"run_notebook failed with terminal state: {'life_cycle_state': 'INTERNAL_ERROR', 'result_state': 'FAILED', 'state_message': \"Cluster '0729-115406-xzfhdyg2' was terminated. Reason: AZURE_QUOTA_EXCEEDED_EXCEPTION (CLIENT_ERROR). Parameters: databricks_error_message:The VM size you are specifying is not available. [details] QuotaExceeded: Operation could not be completed as it results in exceeding approved Total Regional Cores quota. Additional details - Deployment Model: Resource Manager, Location: eastus, Current Limit: 4, Current Usage: 4, Additional Required: 4, (Minimum) New Limit Required: 8. Setup Alerts when Quota reaches threshold. Learn more at https://aka.ms/quotamonitoringalerting . Submit a request for Quota increase at https://aka.ms/ProdportalCRP/#blade/Microsoft_Azure_Capacity/UsageAndQuota.ReactView/Parameters/%7B%22subscriptionId%22:%229c7614db-b553-43c6-b864-5133739e04b5%22,%22command%22:%22openQuotaApprovalBlade%22,%22quotas%22:[%7B%22location%22:%22eastus%22,%22providerId%22:%22Microsoft.Comp ...\\n***WARNING: message truncated. Skipped 1585 bytes of output**\\n\\n\"} and with the errors [{'task_key': 'run_notebook', 'run_id': 533508885115850, 'error': \"Run failed with error message\\n Cluster '0729-115406-xzfhdyg2' was terminated. Reason: AZURE_QUOTA_EXCEEDED_EXCEPTION (CLIENT_ERROR). Parameters: databricks_error_message:The VM size you are specifying is not available. [details] QuotaExceeded: Operation could not be completed as it results in exceeding approved Total Regional Cores quota. Additional details - Deployment Model: Resource Manager, Location: eastus, Current Limit: 4, Current Usage: 4, Additional Required: 4, (Minimum) New Limit Required: 8. Setup Alerts when Quota reaches threshold. Learn more at https://aka.ms/quotamonitoringalerting . Submit a request for Quota increase at https://aka.ms/ProdportalCRP/#blade/Microsoft_Azure_Capacity/UsageAndQuota.ReactView/Parameters/%7B%22subscriptionId%22:%229c7614db-b553-43c6-b864-5133739e04b5%22,%22command%22:%22openQuotaApprovalBlade%22,%22quotas%22:[%7B%22location%22:%22eastus%22,%22providerId%22:%22Microsoft.Comp ...\\n***WARNING: message truncated. Skipped 1585 bytes of output**\\n\\n\"}]","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":877,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1164,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":397,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/databricks/operators/databricks.py","lineno":645,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/databricks/operators/databricks.py","lineno":143,"name":"_handle_databricks_operator_execution"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2025-07-29T12:10:25.559401Z","level":"info","event":"Task instance in failure state","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-29T12:10:25.579233Z","level":"info","event":"Task start","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-29T12:10:25.580200Z","level":"info","event":"Task:<Task(DatabricksSubmitRunOperator): run_notebook>","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-29T12:10:25.580644Z","level":"info","event":"Failure caused by run_notebook failed with terminal state: {'life_cycle_state': 'INTERNAL_ERROR', 'result_state': 'FAILED', 'state_message': \"Cluster '0729-115406-xzfhdyg2' was terminated. Reason: AZURE_QUOTA_EXCEEDED_EXCEPTION (CLIENT_ERROR). Parameters: databricks_error_message:The VM size you are specifying is not available. [details] QuotaExceeded: Operation could not be completed as it results in exceeding approved Total Regional Cores quota. Additional details - Deployment Model: Resource Manager, Location: eastus, Current Limit: 4, Current Usage: 4, Additional Required: 4, (Minimum) New Limit Required: 8. Setup Alerts when Quota reaches threshold. Learn more at https://aka.ms/quotamonitoringalerting . Submit a request for Quota increase at https://aka.ms/ProdportalCRP/#blade/Microsoft_Azure_Capacity/UsageAndQuota.ReactView/Parameters/%7B%22subscriptionId%22:%229c7614db-b553-43c6-b864-5133739e04b5%22,%22command%22:%22openQuotaApprovalBlade%22,%22quotas%22:[%7B%22location%22:%22eastus%22,%22providerId%22:%22Microsoft.Comp ...\\n***WARNING: message truncated. Skipped 1585 bytes of output**\\n\\n\"} and with the errors [{'task_key': 'run_notebook', 'run_id': 533508885115850, 'error': \"Run failed with error message\\n Cluster '0729-115406-xzfhdyg2' was terminated. Reason: AZURE_QUOTA_EXCEEDED_EXCEPTION (CLIENT_ERROR). Parameters: databricks_error_message:The VM size you are specifying is not available. [details] QuotaExceeded: Operation could not be completed as it results in exceeding approved Total Regional Cores quota. Additional details - Deployment Model: Resource Manager, Location: eastus, Current Limit: 4, Current Usage: 4, Additional Required: 4, (Minimum) New Limit Required: 8. Setup Alerts when Quota reaches threshold. Learn more at https://aka.ms/quotamonitoringalerting . Submit a request for Quota increase at https://aka.ms/ProdportalCRP/#blade/Microsoft_Azure_Capacity/UsageAndQuota.ReactView/Parameters/%7B%22subscriptionId%22:%229c7614db-b553-43c6-b864-5133739e04b5%22,%22command%22:%22openQuotaApprovalBlade%22,%22quotas%22:[%7B%22location%22:%22eastus%22,%22providerId%22:%22Microsoft.Comp ...\\n***WARNING: message truncated. Skipped 1585 bytes of output**\\n\\n\"}]","chan":"stdout","logger":"task"}
