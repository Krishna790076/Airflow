{"timestamp":"2025-07-29T11:19:16.213234","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-07-29T11:19:16.218157","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/trigger_databricks_notebook.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-29T11:19:16.417474Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-29T11:19:16.418089Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-29T11:19:16.418705Z","level":"info","event":"Current task name:run_notebook","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-29T11:19:16.419175Z","level":"info","event":"Dag name:databricks_notebook_trigger","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-29T11:19:16.471610","level":"info","event":"Connection Retrieved 'databricks'","logger":"airflow.hooks.base"}
{"timestamp":"2025-07-29T11:19:16.482958","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:19:18.937677","level":"info","event":"Run submitted with run_id: 1099190546858242","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:19:18.938254","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:19:20.399013","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:19:21.823028","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:19:21.823210","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/141109779193595/run/1099190546858242","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:19:21.823284","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:19:52.444519","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:19:53.720280","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:19:53.720744","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/141109779193595/run/1099190546858242","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:19:53.720913","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:20:24.265518","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:20:25.510808","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:20:25.510964","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/141109779193595/run/1099190546858242","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:20:25.511048","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:20:56.207960","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:20:57.556290","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:20:57.556505","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/141109779193595/run/1099190546858242","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:20:57.556587","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:21:27.985724","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:21:30.605514","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:21:30.605750","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/141109779193595/run/1099190546858242","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:21:30.605879","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:22:00.606626","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:22:02.213112","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:22:02.213279","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/141109779193595/run/1099190546858242","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:22:02.213339","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:22:33.215367","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:22:34.697400","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:22:34.697539","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/141109779193595/run/1099190546858242","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:22:34.697588","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:23:05.327969","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:23:06.801392","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:23:06.801679","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/141109779193595/run/1099190546858242","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:23:06.801801","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:23:37.416138","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:23:38.916473","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:23:38.916641","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/141109779193595/run/1099190546858242","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:23:38.916696","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:24:08.917392","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:24:11.793835","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:24:11.794609","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/141109779193595/run/1099190546858242","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:24:11.794780","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:24:41.795323","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:24:44.029956","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:24:44.030112","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/141109779193595/run/1099190546858242","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:24:44.030172","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:25:14.031319","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:25:15.606114","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:25:15.606298","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/141109779193595/run/1099190546858242","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:25:15.606387","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:25:45.608505","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:25:47.963291","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:25:47.963593","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/141109779193595/run/1099190546858242","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:25:47.963720","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:26:17.964285","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:26:19.539625","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:26:19.539824","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/141109779193595/run/1099190546858242","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:26:19.539882","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:26:49.540510","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:26:51.104990","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:26:51.105172","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/141109779193595/run/1099190546858242","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:26:51.105240","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:27:21.105724","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:27:22.810679","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:27:22.810932","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/141109779193595/run/1099190546858242","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:27:22.811040","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:27:52.812327","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:27:54.266028","level":"info","event":"run_notebook in run state: {'life_cycle_state': 'PENDING', 'result_state': '', 'state_message': 'Waiting for cluster'}","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:27:54.266173","level":"info","event":"View run status, Spark UI, and logs at https://adb-919058430982610.10.azuredatabricks.net/?o=919058430982610#job/141109779193595/run/1099190546858242","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:27:54.266228","level":"info","event":"Sleeping for 30 seconds.","logger":"airflow.task.operators.airflow.providers.databricks.operators.databricks.DatabricksSubmitRunOperator"}
{"timestamp":"2025-07-29T11:28:24.267777","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:28:25.639075","level":"info","event":"Using token auth. For security reasons, please set token in Password field instead of extra","logger":"airflow.task.hooks.airflow.providers.databricks.hooks.databricks.DatabricksHook"}
{"timestamp":"2025-07-29T11:28:28.142966","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"AirflowException","exc_value":"run_notebook failed with terminal state: {'life_cycle_state': 'INTERNAL_ERROR', 'result_state': 'FAILED', 'state_message': \"Cluster '0729-111919-6499nezm' was terminated. Reason: AZURE_QUOTA_EXCEEDED_EXCEPTION (CLIENT_ERROR). Parameters: databricks_error_message:The VM size you are specifying is not available. [details] QuotaExceeded: Operation could not be completed as it results in exceeding approved Total Regional Cores quota. Additional details - Deployment Model: Resource Manager, Location: eastus, Current Limit: 4, Current Usage: 4, Additional Required: 4, (Minimum) New Limit Required: 8. Setup Alerts when Quota reaches threshold. Learn more at https://aka.ms/quotamonitoringalerting . Submit a request for Quota increase at https://aka.ms/ProdportalCRP/#blade/Microsoft_Azure_Capacity/UsageAndQuota.ReactView/Parameters/%7B%22subscriptionId%22:%229c7614db-b553-43c6-b864-5133739e04b5%22,%22command%22:%22openQuotaApprovalBlade%22,%22quotas%22:[%7B%22location%22:%22eastus%22,%22providerId%22:%22Microsoft.Comp ...\\n***WARNING: message truncated. Skipped 1585 bytes of output**\\n\\n\"} and with the errors [{'task_key': 'run_notebook', 'run_id': 1099190546858242, 'error': \"Run failed with error message\\n Cluster '0729-111919-6499nezm' was terminated. Reason: AZURE_QUOTA_EXCEEDED_EXCEPTION (CLIENT_ERROR). Parameters: databricks_error_message:The VM size you are specifying is not available. [details] QuotaExceeded: Operation could not be completed as it results in exceeding approved Total Regional Cores quota. Additional details - Deployment Model: Resource Manager, Location: eastus, Current Limit: 4, Current Usage: 4, Additional Required: 4, (Minimum) New Limit Required: 8. Setup Alerts when Quota reaches threshold. Learn more at https://aka.ms/quotamonitoringalerting . Submit a request for Quota increase at https://aka.ms/ProdportalCRP/#blade/Microsoft_Azure_Capacity/UsageAndQuota.ReactView/Parameters/%7B%22subscriptionId%22:%229c7614db-b553-43c6-b864-5133739e04b5%22,%22command%22:%22openQuotaApprovalBlade%22,%22quotas%22:[%7B%22location%22:%22eastus%22,%22providerId%22:%22Microsoft.Comp ...\\n***WARNING: message truncated. Skipped 1585 bytes of output**\\n\\n\"}]","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":877,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1164,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":397,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/databricks/operators/databricks.py","lineno":645,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/databricks/operators/databricks.py","lineno":143,"name":"_handle_databricks_operator_execution"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2025-07-29T11:28:28.254650Z","level":"info","event":"Task instance in failure state","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-29T11:28:28.260740Z","level":"info","event":"Task start","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-29T11:28:28.261384Z","level":"info","event":"Task:<Task(DatabricksSubmitRunOperator): run_notebook>","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-29T11:28:28.261774Z","level":"info","event":"Failure caused by run_notebook failed with terminal state: {'life_cycle_state': 'INTERNAL_ERROR', 'result_state': 'FAILED', 'state_message': \"Cluster '0729-111919-6499nezm' was terminated. Reason: AZURE_QUOTA_EXCEEDED_EXCEPTION (CLIENT_ERROR). Parameters: databricks_error_message:The VM size you are specifying is not available. [details] QuotaExceeded: Operation could not be completed as it results in exceeding approved Total Regional Cores quota. Additional details - Deployment Model: Resource Manager, Location: eastus, Current Limit: 4, Current Usage: 4, Additional Required: 4, (Minimum) New Limit Required: 8. Setup Alerts when Quota reaches threshold. Learn more at https://aka.ms/quotamonitoringalerting . Submit a request for Quota increase at https://aka.ms/ProdportalCRP/#blade/Microsoft_Azure_Capacity/UsageAndQuota.ReactView/Parameters/%7B%22subscriptionId%22:%229c7614db-b553-43c6-b864-5133739e04b5%22,%22command%22:%22openQuotaApprovalBlade%22,%22quotas%22:[%7B%22location%22:%22eastus%22,%22providerId%22:%22Microsoft.Comp ...\\n***WARNING: message truncated. Skipped 1585 bytes of output**\\n\\n\"} and with the errors [{'task_key': 'run_notebook', 'run_id': 1099190546858242, 'error': \"Run failed with error message\\n Cluster '0729-111919-6499nezm' was terminated. Reason: AZURE_QUOTA_EXCEEDED_EXCEPTION (CLIENT_ERROR). Parameters: databricks_error_message:The VM size you are specifying is not available. [details] QuotaExceeded: Operation could not be completed as it results in exceeding approved Total Regional Cores quota. Additional details - Deployment Model: Resource Manager, Location: eastus, Current Limit: 4, Current Usage: 4, Additional Required: 4, (Minimum) New Limit Required: 8. Setup Alerts when Quota reaches threshold. Learn more at https://aka.ms/quotamonitoringalerting . Submit a request for Quota increase at https://aka.ms/ProdportalCRP/#blade/Microsoft_Azure_Capacity/UsageAndQuota.ReactView/Parameters/%7B%22subscriptionId%22:%229c7614db-b553-43c6-b864-5133739e04b5%22,%22command%22:%22openQuotaApprovalBlade%22,%22quotas%22:[%7B%22location%22:%22eastus%22,%22providerId%22:%22Microsoft.Comp ...\\n***WARNING: message truncated. Skipped 1585 bytes of output**\\n\\n\"}]","chan":"stdout","logger":"task"}
